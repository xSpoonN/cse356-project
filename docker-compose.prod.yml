networks:
  agent_network:
    driver: overlay
    attachable: true

volumes:
  osm-data:
  osm-tiles:
  nominatim-data:
  routing-data:
  mongo-data:
  mongo-config:
  import-data:
  portainer_data:

services:
  nginx:
    container_name: nginx
    image: nginx:latest
    ports:
      - '80:80'
    volumes:
      - './docker/nginx.conf:/etc/nginx/nginx.conf'
      - '/var/run/docker.sock:/tmp/docker.sock:ro'
      - './vhost.d:/etc/nginx/vhost.d:ro'
    depends_on:
      - frontend
      - backend
      - glances
    deploy:
      placement:
        constraints:
          - node.role == manager
    logging:
      driver: 'fluentd'
      options:
        tag: nginx
        fluentd-address: fluentd:24224
        fluentd-async-connect: 'true'

  frontend:
    container_name: frontend
    build:
      context: ./frontend/
      dockerfile: ../docker/frontend.prod.Dockerfile
    image: 127.0.0.1:5000/next
    depends_on:
      - fluentd
      - backend
      - nominatim
    restart: always
    deploy:
      placement:
        constraints:
          - node.role == manager

  fluentd:
    container_name: fluentd
    build:
      context: ./docker/
      dockerfile: ./fluentd.Dockerfile
    image: 127.0.0.1:5000/fluentd
    volumes:
      - ./logs/:/var/log/fluentd/
    ports:
      - '24224:24224'
      - '24224:24224/udp'
    deploy:
      placement:
        constraints:
          - node.role == manager

  backend:
    container_name: backend
    image: 127.0.0.1:5000/backend
    build:
      context: ./backend/
      dockerfile: ../docker/backend.prod.Dockerfile
    depends_on:
      - tile-server
      - pgrouting
      - mongo
    restart: always
    extra_hosts:
      host.docker.internal: host-gateway
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 3
      placement:
        constraints:
          - node.role == manager
    logging:
      driver: 'fluentd'
      options:
        tag: backend
        fluentd-address: fluentd:24224
        fluentd-async-connect: 'true'

  mongo:
    container_name: mongo
    image: mongo:latest
    volumes:
      - mongo-data:/data/db
      - mongo-config:/data/configdb
    environment:
      MONGO_INITDB_ROOT_USERNAME: 'root'
      MONGO_INITDB_ROOT_PASSWORD: 'password'
      MONGO_INITDB_DATABASE: 'user'
    restart: always
    deploy:
      placement:
        constraints:
          - node.role == manager

  tile-server:
    container_name: tile-server
    build:
      context: ./docker/
      dockerfile: ./tile-server.Dockerfile
    image: 127.0.0.1:5000/tile-server
    volumes:
      - osm-data:/data/database/
      - osm-tiles:/data/tiles/
      - type: tmpfs
        target: /dev/shm
        tmpfs:
          size: 268435456 # 256MB
    environment:
      DOWNLOAD_PBF: https://grading.cse356.compas.cs.stonybrook.edu/data/us-northeast.osm.pbf
      THREADS: 4
    restart: always
    deploy:
      placement:
        constraints:
          - node.hostname == tile-server

  nominatim:
    container_name: nominatim
    image: mediagis/nominatim:4.4
    environment:
      PBF_URL: https://grading.cse356.compas.cs.stonybrook.edu/data/us-northeast.osm.pbf
      NOMINATIM_PASSWORD: mysecretpassword
      POSTGRES_SHARED_BUFFERS: 2GB # 25% of total memory
      POSTGRES_MAINTENANCE_WORK_MEM: 64MB
      POSTGRES_AUTOVACUUM_WORK_MEM: 2GB
      POSTGRES_EFFECTIVE_CACHE_SIZE: 4GB
    volumes:
      - nominatim-data:/var/lib/postgresql/14/main
      - type: tmpfs
        target: /dev/shm
        tmpfs:
          size: 4294967296 # half of total memory
    restart: always
    deploy:
      placement:
        constraints:
          - node.hostname == nominatim

  pgrouting:
    container_name: pgrouting
    image: pgrouting/pgrouting:latest
    volumes:
      - routing-data:/var/lib/postgresql/data
    environment:
      POSTGRES_PASSWORD: mysecretpassword
      POSTGRES_DB: routing
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U postgres']
      interval: 3s
      timeout: 5s
      retries: 10
    restart: always
    deploy:
      placement:
        constraints:
          - node.hostname == router

  db-import:
    image: 127.0.0.1:5000/db-import
    build:
      context: ./docker/
      dockerfile: ./db-import.Dockerfile
    container_name: db-import
    volumes:
      - import-data:/data
    restart: 'no'
    depends_on:
      - pgrouting
    deploy:
      restart_policy:
        condition: none
      placement:
        constraints:
          - node.hostname == router

  glances:
    image: nicolargo/glances:latest-full
    pid: 'host'
    privileged: true
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    environment:
      TZ: America/New_York
      GLANCES_OPT: -C /glances/conf/glances.conf -w
    ports:
      - 61208:61208
      - 61209:61209
    restart: always
    deploy:
      placement:
        constraints:
          - node.role == manager

  agent:
    image: portainer/agent:2.19.4
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - agent_network
    deploy:
      mode: global
      placement:
        constraints:
          - node.platform.os == linux

  portainer:
    image: portainer/portainer-ce:2.19.4
    command: -H tcp://tasks.agent:9001 --tlsskipverify
    ports:
      - '9443:9443'
      - '9000:9000'
      - '8000:8000'
    volumes:
      - portainer_data:/data
    networks:
      - agent_network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager
