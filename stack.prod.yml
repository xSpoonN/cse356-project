networks:
  agent_network:
    driver: overlay
    attachable: true
  monitor-net:

volumes:
  osm-data:
  mongo-data:
  mongo-config:
  portainer-data:
  nginx-tile-cache:
  tile-server-cache:
  prometheus-data:
  grafana-data:
  loki-data:

x-logging-options: &logging
  logging:
    driver: 'fluentd'
    options:
      tag: '{{.Name}}'
      fluentd-address: 127.0.0.1:24224
      fluentd-async-connect: 'true'

services:
  nginx:
    build:
      context: ./docker/nginx/
      dockerfile: ./nginx.Dockerfile
    image: ktao87/cse356:nginx
    platform: linux/amd64
    ports:
      - '80:80'
    volumes:
      - nginx-tile-cache:/var/cache/tiles
    depends_on:
      - frontend
      - backend
      - search
      - tile-server
    <<: *logging
    deploy:
      restart_policy:
        condition: on-failure
        max_attempts: 5
        delay: 5s
      placement:
        constraints:
          - node.role == manager

  fluentd:
    build:
      context: ./docker/fluentd/
      dockerfile: ./fluentd.Dockerfile
    image: ktao87/cse356:fluentd
    platform: linux/amd64
    ports:
      - '24224:24224'
      - '24224:24224/udp'
    deploy:
      mode: global
      placement:
        constraints:
          - node.role == manager

  frontend:
    build:
      context: ./frontend/
      dockerfile: ../docker/frontend/frontend.prod.Dockerfile
    image: ktao87/cse356:frontend
    platform: linux/amd64
    depends_on:
      - fluentd
      - backend
      - search
    deploy:
      restart_policy:
        condition: none
      placement:
        constraints:
          - node.role == manager

  backend:
    build:
      context: ./backend/
      dockerfile: ../docker/backend/backend.prod.Dockerfile
    image: ktao87/cse356:backend
    platform: linux/amd64
    depends_on:
      - mongo
      - db
    extra_hosts:
      host.docker.internal: host-gateway
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager
    logging:
      driver: 'fluentd'
      options:
        tag: backend
        fluentd-address: fluentd:24224
        fluentd-async-connect: 'true'

  mongo:
    image: mongo:latest
    volumes:
      - mongo-data:/data/db
      - mongo-config:/data/configdb
    environment:
      MONGO_INITDB_ROOT_USERNAME: 'root'
      MONGO_INITDB_ROOT_PASSWORD: 'password'
      MONGO_INITDB_DATABASE: 'user'
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager

  tile-server:
    build:
      context: ./docker/tile-server/
      dockerfile: ./tile.Dockerfile
    image: ktao87/cse356:tile-server
    platform: linux/amd64
    volumes:
      - /var/cache/tiles:/var/cache/tiles
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 7.5GB
        reservations:
          cpus: '4'
          memory: 6GB
      replicas: 3
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.hostname == tile-server

  # Currently trying with file cache
  # tile-cache:
  #   image: bitnami/memcached:latest
  #   environment:
  #     - MEMCACHED_CACHE_SIZE=3500 #in mb
  #     - MEMCACHED_MAX_ITEM_SIZE=31457280 #in bytes
  #     - MEMCACHED_THREADS=2
  #   command: /opt/bitnami/scripts/memcached/run.sh -vv
  #   deploy:
  #     placement:
  #       constraints:
  #         - node.hostname == cache

  search:
    build:
      context: ./search/
      dockerfile: ../docker/search/search.Dockerfile
    image: ktao87/cse356:search
    platform: linux/amd64
    depends_on:
      - db
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager

  db:
    build:
      context: ./docker/db/
      dockerfile: ./db.Dockerfile
    image: ktao87/cse356:db
    platform: linux/amd64
    volumes:
      - osm-data:/var/lib/postgresql/14/main
      - /backup:/backup
      - type: tmpfs
        target: /dev/shm
        tmpfs:
          size: 2048000000 # 2gb
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 7.5GB
        reservations:
          cpus: '4'
          memory: 6GB
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.hostname == db

  agent:
    image: portainer/agent:2.19.4
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/lib/docker/volumes:/var/lib/docker/volumes
    networks:
      - agent_network
    deploy:
      mode: global
      placement:
        constraints:
          - node.platform.os == linux

  portainer:
    image: portainer/portainer-ce:2.19.4
    command: -H tcp://tasks.agent:9001 --tlsskipverify
    ports:
      - '9443:9443'
      - '9000:9000'
      - '8000:8000'
    volumes:
      - portainer-data:/data
    networks:
      - agent_network
    deploy:
      mode: replicated
      replicas: 1
      placement:
        constraints:
          - node.role == manager

  prometheus:
    build:
      context: ./docker/prometheus/
      dockerfile: ./prometheus.Dockerfile
    image: ktao87/cse356:prometheus
    platform: linux/amd64
    volumes:
      - prometheus-data:/prometheus
    networks:
      - monitor-net
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role == manager

  node-exporter:
    image: prom/node-exporter
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - --collector.filesystem.ignored-mount-points
      - '^/(sys|proc|dev|host|etc|rootfs/var/lib/docker/containers|rootfs/var/lib/docker/overlay2|rootfs/run/docker/netns|rootfs/var/lib/docker/aufs)($$|/)'
    ports:
      - 9100:9100
    networks:
      - monitor-net
    deploy:
      mode: global
      restart_policy:
        condition: on-failure

  cadvisor:
    image: gcr.io/cadvisor/cadvisor
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro
    ports:
      - 8088:8080
    networks:
      - monitor-net
    deploy:
      mode: global
      restart_policy:
        condition: on-failure

  grafana:
    build:
      context: ./docker/grafana/
      dockerfile: ./grafana.Dockerfile
    image: ktao87/cse356:grafana
    platform: linux/amd64
    depends_on:
      - prometheus
    ports:
      - 3000:3000
    volumes:
      - grafana-data:/var/lib/grafana
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    networks:
      - monitor-net
    user: '472'
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role==manager

  loki:
    build:
      context: ./docker/loki/
      dockerfile: ./loki.Dockerfile
    image: ktao87/cse356:loki
    platform: linux/amd64
    networks:
      - monitor-net
    volumes:
      - loki-data:/tmp/loki
    deploy:
      restart_policy:
        condition: on-failure
      placement:
        constraints:
          - node.role==manager
